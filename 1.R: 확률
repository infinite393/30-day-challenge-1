확률? 경우의 수 세기
-> 생각할 수 있는 모든 경우의 수 중에서 우리가 관심을 갖는 경우의 수가 차지하는 비율을 생각하는 것

용어
시행: 다양한 결과가 나올 수 있는 어떤 것을 실제로 하는 것. ex)복권긁기
표본공간: 가능한 모든 결과의 모임. 동전던지기의 경우 한 번만 던지면 {앞,뒤}, 두번 던지면 {(앞,앞), (앞,뒤), (뒤,앞), (뒤,뒤)}가 된다. 로또 복권의 경우 814만여 가지의 모든 숫자 조합의 모임이 표본공간이 됨.
사건: 가능한 결과들 중 어떤 요구 사항을 만족하는 것.로또 복권 추첨 결과 '여섯 개의 숫자가 연속이다', '모두 홀수가 나온다'등. 중요한 것은 '사건'이 단 하나의 가능한 결과를 의미하지 않을 수도 있다는 점. '추첨 결과 홀수만 나온다'에 속하는 결과는 '1,3,5,7,9,11' 일 수도 있고 '11,13,15,21,39,45' 일 수도 있음
배반사건: 동시에 일어날 수 없는 두 사건. 로또 복권에서 '모두 짝수가 나온다'와 '모두 홀수가 나온다'는 동시에 일어날 수 없는 사건임.
여사건: 어떤 사건이 일어나지 않는 것. 로또 복권 추첨 결과 '모든 숫자가 짝수다'의 여사건은 '모든 숫자가 짝수인 것은 아니다', 즉 '적어도 숫자 하나는 홀수다'이다. 여기서 '모든 숫자가 짝수다'를 부정한 것이 '모든 숫자가 홀수다'가 아닌 것에 주의

수학적 확률
가능한 모든 결과의 개수
수학적 확률을 사용하려면 시행했을 때 표본공간의 모든 경우가 나올 가능성이 같아야 하는 조건이 필요하다.
ㄴ동전던지기에서 동전이 공평하다면 앞이나 뒤가 나올 확률은 같음/주사위던지기에서 주사위만 공평하다면 1부터 6까지의 눈이 나올 확률은 같음 => 수학적 확률을 적용할 수 있다.

but 동전이 약간 구부러져 있어서(사기도박에서와 같이) 앞면이 나올 확률이 3분의 1, 뒷면이 나올 확률이 3분의 2일 때. 이 경우 가능한 결과가 '앞면'과'뒷면'만 있다고 해서 각각의 확률의 2분의 1이라고 하는 것은 옳지 않다. 
로또 복권 당첨 확률의 경우에도 동일한 가능성의 가정이 확률 계산에서는 핵심이다.

통계적 확률
전체 시행 횟수 중 특정 사건이 일어난 횟수의 비율(수학적 확률 보다 구체적)
일반적으로 통계적 확률은 수학적 확률과 정확히 일치하지 않는다.
but 횟수를 무한정 늘리면 통계적 확률은 결국 수학적 확률에 근접한다. 

극한의 의미
통계적 확률이 수학적 확률에 한없이 가까워진다는 이야기는 시행 횟수가 무한정 늘어나는 일종의 '극한'을 가정했기 때문이다. 여기서 '극한'에는 두 가지 의미가 있다.
첫째, 시행 횟수를 무한히 늘렸을 때. 시행 횟수가 적을 때는 통계적 확률이 수학적 확률에 충분히 가깝지 않지만 횟수가 늘어나면서 통계적 확률은 수학적 확률에 점점 접근한다. 반대로 말하면 횟수가 적을 때는 우연에 의해 수학적 확률에서 벗어나는 경우가 종종 있다 = 표집오차
표집오차는 시행 횟수가 늘어날수록 점점 줄어드는 성질이 있고, 결국에는 0에 가까워다
둘째, 한없이 가까워진다. 0에 가까워진다 and 그럼에도 불구하고 차이가 정확히 0이 되는 일은 사실상 일어나지 않는다.

큰 수의 법칙
표본평균이 자료의 크기가 커짐에 따라 한없이 특정값에 가까워진다. 특정갑 = 기댓값
*동전 던지기 시뮬레이션(R)
베르누이 시행: 가능한 결과가 두 개밖에 없고 성공의 확률이 정해져 있는 확률 시행

#rbinom(난수개수,시행횟수,성공확률)
#0은 실패 1은 성공을 의미=뒷면'실패', 앞면'성공'
x = rbinom(5, 1, 0.5)
x
#결과는 계속 달라진다
> x = rbinom(5, 1, 0.5)
> x
[1] 1 0 0 0 1
일때 통계적 확률 => 2/5=0.4

#통계적 확률 계산하기
> mean(x)
[1] 0.4

#동전던지기 100회 시행시 통계적 확률(5회 시행했을 때보다 0.5에 가까워짐)
> x = rbinom(100, 1, 0.5)
> mean(x)
[1] 0.51

#동전던지기 10000회 시행시 통계적 확률(5회 시행횟을 때보다 0.5에 가까워짐)
> x = rbinom(10000, 1, 0.5)
> mean(x)
[1] 0.4944

-> 통계적 확률은 시행 횟수를 늘릴수록 0.5에 한없이 가까워지지만 정확히 0.5가 되는 일은 사실상 일어나지 않는다. 이것이 통계적 확률에서 말하는 극한의 의미.


통계적 확률로 문제 풀기
시행 횟수가 늘어남에 따라 통계적 확률은 수학적 확률에 한없이 가까워진다. 시행=>R
몬테카를로 시물레이션(몬테카를로 방법) : 시뮬레이션을 통해 수학공식을 적용하지 않고도 확률을 계산하는 방법

R과 몬테카를로 시뮬레이션으로 확률 문제 풀기
문제: 1~5까지의 숫자 카드를 섞어 세 장을 뽑아 세 자리 숫자를 만들 때 그 결과가 310보다 클 확률 구하기
#sample(추첨할 대상, 추첨할 개수, 복원 추출 여부)
#sample(1:5, 3, replace=F) 
#replace=F '한번 뽑은 수는 되돌리지 않는다'
n_simulation = 1000
n_success = 0
for(i in 1:n_simulation){
  x = sample(1:5, 3, replace=F)
  if(x[1] >= 4) n_success = n_success + 1
  if((x[1] == 3) & (x[2] >= 2)) n_success = n_success + 1
}

#몬테카를로시뮬레이션은 확류이기 때문에 시뮬레이션 할 때마다 숫자가 조금씩 달라진다
> n_success
[1] 533
> n_success / n_simulation
[1] 0.533

0.55라는 참값과 같지는 않지만 꽤 근사값이 나온것을 확인할 수 있다.

#시행 횟수를 100만 회로 늘려서 다시 실행
> n_success
[1] 550593
> n_success / n_simulation
[1] 0.550593

0.55와 거의 일치하는 것을 볼 수 있다
시행 횟수를 늘리면 늘릴수록 컴퓨터가 표시할 수 있는 한도 내에서는 0.55와 구별할 수 없을 정도로 가까워지므로 그냥 0.55로 표시될것이다.


몬테카를로 방법으로 원주율 계산하기

n_sim = 1000
x = vector(length=n_sim)
y = vector(length=n_sim)
res = 0
for(i in 1:n_sim) {
  x[i] = runif(1)
  y[i] = runif(1)
  if(x[i]^2 + y[i]^2 < 1) res = res + 1
}

> print(4 * res / n_sim)
[1] 3.184


정확도를 높이기 위해 시물레이션 횟수를 10만 번으로 늘림
n_sim = 100000
x = vector(length=n_sim)
y = vector(length=n_sim)
res = 0
for(i in 1:n_sim) {
  x[i] = runif(1)
  y[i] = runif(1)
  if(x[i]^2 + y[i]^2 < 1) res = res + 1
}

> print(4 * res / n_sim)
[1] 3.14152

3.14와 가까워짐
신기하당


#뽑힌 값들이 좌표평면상에서 어디에 위치하는지 확인
circle = function(x) sqrt(1-x^2)
plot(x, y, xlab='X', ylab='Y')
curve(circle, from=0, to=1, add=T, col='blue', lwd=2)

-> 파란 선으로 쵸시된, 원점을 중심으로 반지름이 1인 원 안에 있는 점들의 비율이 바로 사분원의 넓이에 대한 근사값이다.
  여기에 4를 곱한 값이 원주율에 대한 근사값.
=몬테카를로 방법을 이용하면 시뮬레이션을 통해 이렇게 알지 못하는 값을 구할 수 있는 경우가 종종 있다. 수학적 지식이 전혀 없어도! 오오...


몬티홀 문제
세개의 문. 두개는 염소(꽝), 하나는 자동차. 세개 문 중 하나를 선택.
-> 참가자가 문을 선택했을 때 선택하지 않은 문 중 염소가 있는 문을 열어서 보여주고, 문을 바꿀 기회를 줌
=> 이때 선택한 문을 바꾸는 것과 그렇지 않는 것 중 어느 쪽이 차를 선택할 확률이 높을까?

---> 바꾸는 것이 낫다
= 진행자가 염소를 보여준 뒤 문을 바꾸지 않으면 차를 얻을 확률이 3분의 1이지만 바꾸면 3분의 2가 된다

n_sim = 1000
doors = 1:3
success = 0

for (i in 1:n_sim) {
  # 세 개의 문 중 차의 위치를 고른다
  car = sample(doors, 1)
  
  #차가 없는 곳에 염소들을 배치한다
  if(car == 1) goat = c(2,3)
  else if (car == 2) goat = c(1,3)
  else goat = c(1,2)
  
  #참가자가 문을 고른다
  pick = sample(doors, 1)
  
  #참가자가 고르지 않은 문 중 염소가 있는 문을 찾는다
  goat_not_picked = goat[goat != pick]

  #참가자가 고르지 않은 문 중 염소가 있는 문 하나를 열어준다
  if(length(goat_not_picked) > 1) open = sample(goat_not_picked, 1)
  else open = goat_not_picked
  
  #바꾸지 않고 처음 고른 문이 차가 있는 문이면 '성공'으로 기록
  if(pick == car) success = success + 1
}

> #총 시행 중 '성공'의 비율
> success / n_sim
[1] 0.331

=> 세 개의 문 중 하나를 골라 차를 배치, 나머지 문에는 염소를 배치, '참가자'가 하나의 문을 선택하면 진행자가 그 문이 아닌 것 중 염소가 있는 문을 열어 보여주고 참가자는 선택을 바꾸지 않은 채로 차가 있는지 확인하게 한다.
   이것을 n_sim회만큼 반복한 뒤 총 성공 횟수를 success라는 변수에 저장('성공'할 때마다 success에 1을 더하는 것)
   마지막 줄에서 성공률을 계산한다. 이 코드를 실행하면 0.33과 크게 다르지 않은 값이 나온다.

#앞에 코드에서 선택한 문을 바꾸는 명령어를 추가
n_sim = 1000
doors = 1:3
success = 0

for (i in 1:n_sim) {
  # 세 개의 문 중 차의 위치를 고른다
  car = sample(doors, 1)
  
  #차가 없는 곳에 염소들을 배치한다
  if(car == 1) goat = c(2,3)
  else if (car == 2) goat = c(1,3)
  else goat = c(1,2)
  
  #참가자가 문을 고른다
  pick = sample(doors, 1)
  
  #참가자가 고르지 않은 문 중 염소가 있는 문을 찾는다
  goat_not_picked = goat[goat != pick]

  #참가자가 고르지 않은 문 중 염소가 있는 문 하나를 열어준다
  if(length(goat_not_picked) > 1) open = sample(goat_not_picked, 1)
  else open = goat_not_picked
  
  #참가자는 고른 문을 바꾼다
  pick = doors[(doors != pick) & (doors != open)]
  
  #바꾸어 선택한 문이 차가 있는 문이면 '성공'으로 기록
  if(pick == car) success = success + 1
}

> #총 시행 중 '성공'의 비율
> success / n_sim
[1] 0.692

-> 문을 바꿨을 때 차를 받을 확률이 높아짐

설명:
참가자가 처음에 염소가 있는 문을 고른 경우 문을 바꾸면 반드시 차를 얻게된다
반대로 참가자가 처음에 차가 있는 문을 고른 경우 진행자가 어떤 문을 고르든 상관없이 문을 바꾸면 차를 얻지 못한다
=> 문을 바꾸는 결정을 하는 참가자가 차를 얻을 확률은 처음에 염소가 있는 문을 고를 확률가 같다
이는 3분의 2이고, 문을 바꾸지 않는 경우의 3분의 1에 비해 두배 높은 확률이다.




출처 <3일 만에 끝내는 코딩+통계>

